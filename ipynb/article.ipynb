{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water flows, so does information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GitHub repository needed to reproduce this notebook can be found [here](https://github.com/davidbrochart/hydro_forward_backward).\n",
    "\n",
    "In this notebook I will show that the information about the streamflow at a point on a river can be transfered to any point on a river of the same hydrological basin, not only downstream but also upstream. It comes from the fact that a part of the water present in the streamflow of a river comes from other rivers that flow into it. This hierarchical relationship can be used by algorithms to pass information. Possible applications can be found in situations where available data is not sufficient to unambiguously calibrate a model, for instance when sparse measurements of water level are available, as it is the case for satellite-based estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hydrological network is of hierarchical nature. As we can see in the figure below, where the Amazon basin's river network is represented, lots of small streams flow into bigger ones, which get bigger and bigger as they collect more flows (while also being less and less numerous), and so on until only one river remains and reaches the basin's outlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.sankey import Sankey\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from pandas import DataFrame\n",
    "import sys\n",
    "sys.path.append('../py')\n",
    "from models import gr4j, delay\n",
    "from misc import get_kde, uniform_density, lnprob_from_density, plot_series, dist_map\n",
    "import mcmc\n",
    "from IPython.display import Image\n",
    "Image(\"../data/hydrosheds_amazon_large.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will limit the scope of this study to the simplest form of network - a linear one, where we have only one river that flows through several subbasins. In the figure below, we denote these subbasins by *b<sub>n</sub>*, while the basins that include the upstream subbasins are called *B<sub>n</sub>* and defined by:\n",
    "\n",
    "*B<sub>0</sub> = {b<sub>0</sub>}*\n",
    "\n",
    "*B<sub>1</sub> = {b<sub>0</sub>, b<sub>1</sub>}*\n",
    "\n",
    "...\n",
    "\n",
    "*B<sub>n</sub> = {b<sub>0</sub>, b<sub>1</sub>, ..., b<sub>n</sub>}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[])\n",
    "sankey = Sankey(ax=ax, unit=None)\n",
    "sankey.add(flows=[1, -1], trunklength=2, patchlabel='$b_0$')\n",
    "ws_nb = 5\n",
    "for i in range(1, ws_nb):\n",
    "    sankey.add(flows=[1, -1], trunklength=2, patchlabel=f'$b_{i}$', prior=i-1, connect=(1, 0))\n",
    "sankey.finish()\n",
    "plt.title('Subbasins along a linear river network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load some precipitation data. It doesn't matter very much where it comes from, it just looks like a plausible precipitation time series (see figure below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.load('../data/p.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a constant potential evapotranspiration, even though this is not very plausible, but it is not very important here. The precipitation and potential evapotranspiration are uniform across all subbasins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()\n",
    "df['p'] = p\n",
    "df['e'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 365 # show last year's data\n",
    "columns = {'e': '$E$', 'p': '$P$'}\n",
    "df[['p', 'e']][-days:].rename(columns=columns).plot(figsize=(17, 5))\n",
    "plt.legend()\n",
    "plt.title('Precipitation (P) and potential evapotranspiration (E) over every subbasin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate synthetic streamflow data, we choose quite an arbitrary hydrological model, and feed it with the precipitation and potential evapotranspiration data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = [500, 0, 50, 5]\n",
    "g = gr4j(x_true) # arbitrary rainfall-runoff model\n",
    "df['q_true_0'] = g.run([df.p.values, df.e.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for our basin *B<sub>0</sub>*. Now we want the stream at its outlet to flow into another subbasin, which itself flows into another subbasin, etc. We will suppose that all subbasins have the same area, and that the time it takes for the water to flow from the outlet of a subbasin to the outlet of the next one is the same for every subbasin, and can be described by a simple delay in the streamflow signal. From this we can compute the streamflow at the outlet of a basin recursively from the streamflow at the outlet of its upstream basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_true = 3 # 3 days for the water from a subbasin to flow into the next\n",
    "d = delay(d_true)\n",
    "for i in range(1, ws_nb):\n",
    "    area_head = i\n",
    "    area_tail = 1\n",
    "    df[f'q_true_{i}'] = (d.run(df[f'q_true_{i-1}'].values) * area_head + df.q_true_0.values * area_tail) / (area_head + area_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to convert our streamflows to water levels, which will be the measured quantity. This is usually done through a rating curve. Here we will just take the water level to be equal to the square root of the streamflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ws_nb):\n",
    "    df[f'h_true_{i}'] = np.sqrt(df[f'q_true_{i}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simulate a situation where water level is partially known, we want to remove information from our synthetic water level time series. This can be done by inserting missing values and by adding noise. It is similar to the type of data we can find in satellite estimates. The noise is chosen to be Gaussian around the true value, and the remaining data is spread in time accross the subbasins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = 3 * 30 # keep one water level measure every 3 months for each subbasin\n",
    "offset = downsample // ws_nb\n",
    "std = 0.5\n",
    "for i in range(ws_nb):\n",
    "    # noise is additive gaussian\n",
    "    h_noised = np.random.normal(df[f'h_true_{i}'].values, std, df.p.values.size)\n",
    "    h = np.ones_like(h_noised) * np.nan\n",
    "    h[offset*i::downsample] = h_noised[offset*i::downsample]\n",
    "    df[f'h{i}'] = h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows that the information we have about the water levels is spread accross the subbasins, not only in space but also in time. The remaining of this study presents the [forward-backward algorithm](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm), which is well suited for taking advantage of such a distributed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 365 # show last year's data\n",
    "plt.figure(figsize=(17, 5))\n",
    "for i in range(ws_nb):\n",
    "    plt.plot(df[f'h_true_{i}'].tail(days), label=f'$True({i})$')\n",
    "for i in range(ws_nb):\n",
    "    plt.scatter(df.tail(days).index, df[f'h{i}'].tail(days), label=f'$Measured({i})$')\n",
    "plt.legend()\n",
    "plt.title('Spread water level information accross subbasins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to pass the information forward (i.e. downstream), just like water flows. We start by calibrating *B<sub>0</sub>*'s model using the available measurements (*P, E, H<sub>0</sub>*) over it. The calibration tries to find the parameters of the model that best fit the observed data, but instead of running an optimization algorithm like the [downhill simplex algorithm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin.html#scipy.optimize.fmin), we use a [Markov chain Monte Carlo algorithm](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) (MCMC). While the former gives us the optimal value of the model parameters given the measurements *as is*, the latter gives us their probability density by taking uncertainty in the measured streamflow into account. For instance, the poor measurements available might not be sufficient to determine the model parameters precisely, but there are more measurements downstream that might help. The idea is then to use a model of *B<sub>1</sub>* that makes use of *B<sub>0</sub>* and *b<sub>1</sub>*'s models, and to calibrate this *dual* model with the measurements over *B<sub>1</sub>*. Note that the dual model consists of twice as many parameters as a single model (plus one parameter for the propagation delay), which could be an issue if we didn't have any prior information about these parameters. But it is not the case: the calibration of *B<sub>0</sub>*'s model helped us know its parameters better. When this information is used during the calibration of *B<sub>1</sub>*'s dual model, it constrains the possible values of the parameters of *b<sub>1</sub>*'s model. In this process, information passes from *B<sub>0</sub>* to *b<sub>1</sub>*. Now, if we repeat the same operations for *B<sub>1</sub>* (whose parameters have information from *H<sub>0</sub>* and *H<sub>1</sub>*) and *b<sub>2</sub>*, using information from *H<sub>2</sub>*, we can see that each calibration of a model uses information from its upstream subbasins. And if we keep on doing it until the outlet, we effectively make the information flow downstream.\n",
    "\n",
    "Note that the basic mechanism in which information is exchanged between two basins is the calibration of a dual model, i.e. a model that splits a basin in two submodels. It is through the calibration of this dual model that information can be transfered between the parameters of the two submodels, and consequently between the streamflows simulated by the submodels.\n",
    "\n",
    "Let's first get the posterior probability distribution for the model parameters of *B<sub>0</sub>*, given a water level *H<sub>0</sub>*. We take a uniform distribution for the prior of these parameters, because we don't know anything about them. For the uncertainty in the water level measurements, we take a Gaussian around the observed values, just like the noise we added on the true water level (but applied to the measured water level since we don't know the true one).\n",
    "\n",
    "Since the hydrological model can only simulate streamflows, we need a way to transform a streamflow signal to a water level signal. We use the same technique as in [this post](http://davidbrochart.github.io/streamflow/stage/2017/02/12/waterlevel.html) (probability distribution mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peq = df[['p', 'e']]\n",
    "peq['h'] = df['h0']\n",
    "warmup = 365 * 2 # discard two first years for the warmup of the model\n",
    "\n",
    "# prior probability distribution is uniform\n",
    "x_range = ((0.1, 1e4), (-1, 1), (0.1, 1e3), (0.1, 1e2))\n",
    "x_prior = [uniform_density(*r) for r in x_range]\n",
    "lnprob_prior = [lnprob_from_density(p, *r) for p, r in zip(x_prior, x_range)]\n",
    "\n",
    "def lnprob(x):\n",
    "    # prior\n",
    "    lnp = 0\n",
    "    for i, v in enumerate(x):\n",
    "        lnp += lnprob_prior[i](v)\n",
    "    if not np.isfinite(lnp):\n",
    "        return -np.inf, np.ones_like(peq.p.values) * np.inf\n",
    "\n",
    "    h_obs = peq.h.values\n",
    "    q_sim = gr4j(x).run([peq.p.values, peq.e.values])\n",
    "    h_sim = np.hstack((np.full(warmup, np.nan), dist_map(q_sim[warmup:], h_obs[warmup:])))\n",
    "    # remove warmup and missing values\n",
    "    df = DataFrame({'h_sim': h_sim, 'h_obs': h_obs})[warmup:].dropna()\n",
    "    std2 = std * std\n",
    "    # error on measured water level is gaussian with standard deviation std\n",
    "    return lnp + np.sum(-np.square(df.h_sim.values - df.h_obs.values) / (2 * std2) - np.log(np.sqrt(2 * np.pi * std2))), (q_sim, h_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nb = 1_000 # number of samples generated by MCMC\n",
    "burnin = sample_nb // 10 # number of burnin samples\n",
    "x_start = [100, 0, 10, 1] # arbitrary initial parameter values for MCMC\n",
    "x0 = x_start\n",
    "sampler = mcmc.Sampler(x0, lnprob)\n",
    "samples, qh_sim = sampler.run(sample_nb, burnin)\n",
    "q_sim = np.empty((sample_nb, *peq.p.values.shape))\n",
    "h_sim = np.empty((sample_nb, *peq.p.values.shape))\n",
    "for i in range(sample_nb):\n",
    "    q_sim[i, :] = qh_sim[i][0]\n",
    "    h_sim[i, :] = qh_sim[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(ensemble=h_sim[:, -days:], true=df.h_true_0.values[-days:], measure=df.h0.values[-days:], title='Simulated water level at the outlet of $B_0$ using measured water level $H_0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(ensemble=q_sim[:, -days:], true=df.q_true_0.values[-days:], title='Simulated streamflow at the outlet of $B_0$ using measured water level $H_0$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows the posterior probability distribution of *B<sub>0</sub>*'s model parameters (using [Kernel Density Estimation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html)). We can see that they are more or less centered on their true value (vertical line), with some uncertainty. It can happen that the model is way off the true value for a particular parameter, and uses another parameter to compensate for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(dist, x_true):\n",
    "    x_nb = len(dist)\n",
    "    f, ax = plt.subplots(1, x_nb)\n",
    "    f.set_figwidth(x_nb * 4)\n",
    "    for i in range(x_nb):\n",
    "        x, y = dist[i]\n",
    "        ax[i].plot(x, y)\n",
    "        ax[i].axvline(x_true[i], color='red', alpha=0.3)\n",
    "        ax[i].set_title(f'$X_{i+1}$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b0 = [get_kde(samples[:, i]) for i in range(4)]\n",
    "plot_dist(x_b0, x_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *B<sub>1</sub>*, with discharge *Q<sub>1</sub>*, we need a model that consists of the models of *B<sub>0</sub>* (with its propagation delay) and *b<sub>1</sub>*. Thus the *lnprob* function has to be a little more complex. Also, it has to take into account the prior information on the parameters of *B<sub>0</sub>*'s model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peq = df[['p', 'e']]\n",
    "peq['h'] = df['h1']\n",
    "# prior probability distribution is uniform for subbasin b1\n",
    "x_range = ((0.1, 1e4), (-1, 1), (0.1, 1e3), (0.1, 1e2))\n",
    "# prior probability distribution for subbasin b0 comes from previous iteration\n",
    "x_b1 = [uniform_density(*r) for r in x_range]\n",
    "d_range = (0, 10)\n",
    "d_prior = uniform_density(*d_range)\n",
    "lnprob_prior = [lnprob_from_density(p, *r) for p, r in zip(x_b0, x_range)]\n",
    "lnprob_prior += [lnprob_from_density(d_prior, *d_range)]\n",
    "lnprob_prior += [lnprob_from_density(p, *r) for p, r in zip(x_b1, x_range)]\n",
    "\n",
    "def lnprob(x):\n",
    "    # prior\n",
    "    lnp = 0\n",
    "    for i, v in enumerate(x):\n",
    "        lnp += lnprob_prior[i](v)\n",
    "    if not np.isfinite(lnp):\n",
    "        return -np.inf, np.ones_like(peq.p.values) * np.inf\n",
    "\n",
    "    h_obs = peq.h.values\n",
    "    std2 = std * std\n",
    "    x_head = x[:5]\n",
    "    g_head = gr4j(x_head)\n",
    "    x_tail = x[5:]\n",
    "    g_tail = gr4j(x_tail)\n",
    "    q_sim = (g_head.run([peq.p.values, peq.e.values]) + g_tail.run([peq.p.values, peq.e.values])) / 2\n",
    "    h_sim = np.hstack((np.full(warmup, np.nan), dist_map(q_sim[warmup:], h_obs[warmup:])))\n",
    "    df = DataFrame({'h_sim': h_sim, 'h_obs': h_obs})[warmup:].dropna()\n",
    "    return lnp + np.sum(-np.square(df.h_sim.values - df.h_obs.values) / (2 * std2) - np.log(np.sqrt(2 * np.pi * std2))), (q_sim, h_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start = 1\n",
    "x0 = [x_b0[i][0][np.argmax(x_b0[i][1])] for i in range(4)] + [d_start] + x_start\n",
    "sampler = mcmc.Sampler(x0, lnprob)\n",
    "samples, qh_sim = sampler.run(sample_nb, burnin)\n",
    "q_sim = np.empty((sample_nb, *peq.p.values.shape))\n",
    "h_sim = np.empty((sample_nb, *peq.p.values.shape))\n",
    "for i in range(sample_nb):\n",
    "    q_sim[i, :] = qh_sim[i][0]\n",
    "    h_sim[i, :] = qh_sim[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nb = 5\n",
    "f, ax = plt.subplots(1, x_nb)\n",
    "f.set_figwidth(x_nb * 3.2)\n",
    "for i in range(x_nb):\n",
    "    x, y = get_kde(samples[:, i])\n",
    "    if i < 4:\n",
    "        p = ax[i].plot(*x_b0[i], alpha=0.1)\n",
    "        ax[i].axvline(x_true[i], color='r', alpha=0.3)\n",
    "        ax[i].set_title(f'$X_{i+1}$')\n",
    "    else:\n",
    "        ax[i].axvline(d_true, color='r', alpha=0.3)\n",
    "        ax[i].set_title(f'$d$')\n",
    "    ax[i].plot(x, y, color=p[0].get_color())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows the posterior probability distribution for the parameters of *b<sub>1</sub>*'s model. Information from *B<sub>0</sub>*'s model parameters was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b1 = [get_kde(samples[:, i]) for i in range(5, 9)]\n",
    "plot_dist(x_b1, x_true[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to continue this process downstream, we could just create a model which includes the models of all its upstream subbasins. But that would not scale, first from a computational point of view, because each model adds 5 new parameters and the MCMC algorithm needs to run the model N times for each sample (where N is the total number of parameters), and then from a problem complexity point of view, because each time we add a parameter we add a dimension to the space that the MCMC algorithm has to explore. Even if the prior information we have on the parameters limits this space, it is always very important to limit the number of parameters for the algorithm to converge.\n",
    "\n",
    "To prevent the problem complexity from growing, we can reduce our dual model to a single model. Indeed, we should now have a dual model that can produce (i.e. simulate) streamflow data with a better precision than the measured streamflow, since we also used the information in the streamflow of its upstream basin. All we need to do is to get the posterior probability distribution for the parameters of this single model using the simulated streamflow from the dual model. Fortunately, we already computed the streamflow of the dual model previously when we ran the MCMC algorithm. From this ensemble of streamflow time series, we get the streamflow probability density at each time step (using KDE), and use it for the calibration of the single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kde = 10 # KDE points\n",
    "q_kde = np.empty((2, n_kde, q_sim.shape[1]))\n",
    "for i in range(q_kde.shape[2]):\n",
    "    q_kde[:, :, i] = get_kde(q_sim[:, i], nb=n_kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(ensemble=h_sim[:, -days:], true=df.h_true_1.values[-days:], measure=df.h1.values[-days:], title='Water level at the outlet of $B_1$ (dual model)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(ensemble=q_sim[:, -days:], true=df.q_true_1.values[-days:], title='Streamflow at the outlet of $B_1$ (dual model)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the calibration of the single model, we compute the posterior probability as the product of the probabilities of the simulated streamflow given the observed streamflow (which has been simulated by the dual model). This implies that the data is independent, and for that to be true we need to take into account that the streamflow signal is autocorrelated, i.e. the streamflow at time *t<sub>0</sub>* is *not* independent from the streamflow at time *t<sub>1</sub>* if *t<sub>0</sub>* and *t<sub>1</sub>* are too close. Thus we cannot take the streamflow values at each time step, and instead we must take e.g. one data every six months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peq = df[['p', 'e']]\n",
    "sim_step = 365 // 2 # take one streamflow data every 6 months when computing posterior probability\n",
    "\n",
    "def lnprob(x):\n",
    "    q_sim = gr4j(x).run([peq.p.values, peq.e.values])\n",
    "    lnp = 0\n",
    "    for i in range(warmup, q_sim.size, sim_step):\n",
    "        lnp += lnprob_from_density(q_kde[:, :, i])(q_sim[i])\n",
    "    return lnp, q_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0 = x_start\n",
    "sampler = mcmc.Sampler(x0, lnprob)\n",
    "samples, q_sim = sampler.run(sample_nb, burnin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_sim = np.array(q_sim)\n",
    "plot_series(ensemble=h_sim[:, -days:], true=df.h_true_1.values[-days:], measure=df.h1.values[-days:], title='Water level at the outlet of $B_1$ (single model)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(ensemble=q_sim[:, -days:], true=df.q_true_1.values[-days:], title='Streamflow at the outlet of $B_1$ (single model)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are back in the situation we started in: we can create a dual model that consists of the models of *B<sub>1</sub>* and *b<sub>2</sub>*, etc. The following is the full algorithm which corresponds to the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_lnprob(peq, lnprob_prior, area_head, area_tail, q_kde=None):\n",
    "    def lnprob(x):\n",
    "        lnp = 0\n",
    "        for i, v in enumerate(x):\n",
    "            lnp += lnprob_prior[i](v)\n",
    "        if not np.isfinite(lnp):\n",
    "            return -np.inf, np.ones_like(peq.p.values) * np.inf\n",
    "\n",
    "        x_head = x[:5] # this includes the delay in the gr4j model\n",
    "        g_head = gr4j(x_head)\n",
    "        if area_tail > 0:\n",
    "            x_tail = x[5:]\n",
    "            g_tail = gr4j(x_tail)\n",
    "            q_tail = g_tail.run([peq.p.values, peq.e.values])\n",
    "        else:\n",
    "            q_tail = 0\n",
    "        q_sim = (g_head.run([peq.p.values, peq.e.values]) * area_head + q_tail * area_tail) / (area_head + area_tail)\n",
    "        if q_kde is None:\n",
    "            # observation is measured water level\n",
    "            h_obs = peq.h_obs.values\n",
    "            h_sim = np.hstack((np.full(warmup, np.nan), dist_map(q_sim[warmup:], h_obs[warmup:])))\n",
    "            df = DataFrame({'h_sim': h_sim, 'h_obs': h_obs})[warmup:].dropna()\n",
    "            std2 = std * std\n",
    "            return lnp + np.sum(-np.square(df.h_sim.values - df.h_obs.values) / (2 * std2) - np.log(np.sqrt(2 * np.pi * std2))), q_sim\n",
    "        else:\n",
    "            # observation is simulated streamflow\n",
    "            lnp_q = 0\n",
    "            for i in range(warmup, q_sim.size, sim_step):\n",
    "                lnp_q += lnprob_from_density(q_kde[:, :, i])(q_sim[i])\n",
    "            return lnp + lnp_q, q_sim\n",
    "    return lnprob\n",
    "\n",
    "q_ensemble = {}\n",
    "for ws_i in range(ws_nb):\n",
    "    peq = df[['p', 'e']]\n",
    "    peq['h_obs'] = df[f'h{ws_i}']\n",
    "    if ws_i == 0:\n",
    "        area_head = 1\n",
    "        area_tail = 0\n",
    "        # prior probability distribution is uniform for head basin\n",
    "        x0 = x_start\n",
    "        x_prior = [uniform_density(*r) for r in x_range]\n",
    "        lnprob_prior = [lnprob_from_density(p, *r) for p, r in zip(x_prior, x_range)]\n",
    "    else:\n",
    "        area_head = ws_i\n",
    "        area_tail = 1\n",
    "        x0 = [xy[0][np.argmax(xy[1])] for xy in x_head]\n",
    "        x0 += [d_start] + x_start\n",
    "        # prior probability distribution is uniform for tail basin\n",
    "        lnprob_prior = [lnprob_from_density(p, *r) for p, r in zip(x_head, x_range)]\n",
    "        lnprob_prior += [lnprob_from_density(uniform_density(*d_range), *d_range)]\n",
    "        x_tail = [uniform_density(*r) for r in x_range]\n",
    "        lnprob_prior += [lnprob_from_density(p, *r) for p, r in zip(x_tail, x_range)]\n",
    "    lnprob = get_lnprob(peq, lnprob_prior, area_head, area_tail)\n",
    "    # run MCMC\n",
    "    sampler = mcmc.Sampler(x0, lnprob)\n",
    "    samples, q_sim = sampler.run(sample_nb, burnin)\n",
    "    # get simulated streamflow and uncertainty\n",
    "    q_sim = np.array(q_sim)\n",
    "    q_ensemble[f'f{ws_i}'] = q_sim\n",
    "    # plot updated streamflow\n",
    "    plot_series(ensemble=q_sim[:, -days:], true=df[f'q_true_{ws_i}'].values[-days:], title=f'Streamflow at the outlet of $B_{ws_i}$')\n",
    "    if (ws_i > 0) and (ws_i < ws_nb - 1):\n",
    "        # reduce dual model to single model\n",
    "        peq = df[['p', 'e']]\n",
    "        x_prior = [uniform_density(*r) for r in x_range]\n",
    "        lnprob_prior = [lnprob_from_density(p, *r) for p, r in zip(x_prior, x_range)]\n",
    "        q_kde = np.empty((2, n_kde, q_sim.shape[1]))\n",
    "        for i in range(q_kde.shape[2]):\n",
    "            q_kde[:, :, i] = get_kde(q_sim[:, i], nb=n_kde)\n",
    "        lnprob = get_lnprob(peq, lnprob_prior, 1, 0, q_kde)\n",
    "        x0 = x_start\n",
    "        sampler = mcmc.Sampler(x0, lnprob)\n",
    "        samples, q_sim = sampler.run(sample_nb, burnin)\n",
    "    x_head = [get_kde(samples[:, i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the information forward results in the downstream basins benefiting from more information than the upstream basins, since the information accumulates at each iteration. So for instance *Q<sub>4</sub>* is better known than *Q<sub>0</sub>* after the update. But we can feel that an information on a downstream basin can also constrain an upstream basin. Take the extreme situation where it never rains on a downstream subbasin, then the streamflow at its outlet has to come from the upstream basin.\n",
    "\n",
    "The solution is to pass the information backward (i.e. upstream). This is less intuitive since water doesn't flow upstream, but from the information point of view it works both ways: when we calibrate *b<sub>1</sub>*'s model using *B<sub>0</sub>*'s model, we can say that the information in *Q<sub>0</sub>* constrains the possible values of *Q<sub>1</sub>* further (information passes forward), or we can equivalently say that the information in *Q<sub>1</sub>* constrains the possible values of *Q<sub>0</sub>* further (information passes backward). Now if instead of starting from the two first basins we start from the two last ones, and repeat this process by going upstream, we effectively make the information flow backward.\n",
    "\n",
    "We start by calibrating *B<sub>4</sub>*'s model using the measured water level *H<sub>4</sub>*, and we do the same with *B<sub>3</sub>* and *H<sub>3</sub>* (which gives us some information on its parameters). Then we create a dual model consisting of a model for *B<sub>3</sub>* (with prior information on its parameters thanks to the previous calibration) and a model for *b<sub>4</sub>* (with no prior information), and we calibrate it with the ensemble of simulated streamflows for *B<sub>4</sub>* that we previously generated. This gives an ensemble of simulated streamflows for *B<sub>3</sub>* that have used information from the measured water levels *H<sub>3</sub>* and *H<sub>4</sub>*. We can now repeat the same process with the dual model consisting of *B<sub>2</sub>* and *b<sub>3</sub>*, using the ensemble of simulated streamflows for *B<sub>3</sub>* previously generated, etc. The following is the full algorithm corresponding to the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_lnprob(peq, lnprob_prior, area_head, area_tail, q_kde=None):\n",
    "    def lnprob(x):\n",
    "        lnp = 0\n",
    "        for i, v in enumerate(x):\n",
    "            lnp += lnprob_prior[i](v)\n",
    "        if not np.isfinite(lnp):\n",
    "            return -np.inf, np.ones_like(peq.p.values) * np.inf\n",
    "        x_head = x[:4] # don't include delay because we return q_head\n",
    "        g_head = gr4j(x_head)\n",
    "        if area_tail > 0:\n",
    "            x_tail = x[5:]\n",
    "            g_tail = gr4j(x_tail)\n",
    "            q_tail = g_tail.run([peq.p.values, peq.e.values])\n",
    "        else:\n",
    "            q_tail = 0\n",
    "        q_head = g_head.run([peq.p.values, peq.e.values])\n",
    "        if len(x) > 4:\n",
    "            d = delay(x[4])\n",
    "            q_head_delayed = d.run(q_head)\n",
    "        else:\n",
    "            q_head_delayed = q_head\n",
    "        q_sim = (q_head_delayed * area_head + q_tail * area_tail) / (area_head + area_tail)\n",
    "        if q_kde is None:\n",
    "            # observation is measured water level\n",
    "            h_obs = peq.h_obs.values\n",
    "            h_sim = np.hstack((np.full(warmup, np.nan), dist_map(q_sim[warmup:], h_obs[warmup:])))\n",
    "            df = DataFrame({'h_sim': h_sim, 'h_obs': h_obs})[warmup:].dropna()\n",
    "            std2 = std * std\n",
    "            return lnp + np.sum(-np.square(df.h_sim.values - df.h_obs.values) / (2 * std2) - np.log(np.sqrt(2 * np.pi * std2))), q_head\n",
    "        else:\n",
    "            # observation is simulated streamflow\n",
    "            lnp_q = 0\n",
    "            for i in range(warmup, q_sim.size, sim_step):\n",
    "                lnp_q += lnprob_from_density(q_kde[:, :, i])(q_sim[i])\n",
    "            return lnp + lnp_q, q_head\n",
    "    return lnprob\n",
    "\n",
    "for ws_i in range(ws_nb-1, 0, -1):\n",
    "    if ws_i == ws_nb - 1:\n",
    "        nb = 2\n",
    "    else:\n",
    "        nb = 1\n",
    "    for n in range(nb-1, -1, -1):\n",
    "        # head basin, no prior information\n",
    "        peq = df[['p', 'e']]\n",
    "        peq['h_obs'] = df[f'h{ws_i-1+n}']\n",
    "        x_prior = [uniform_density(*r) for r in x_range]\n",
    "        lnprob_prior = [lnprob_from_density(p, *r) for p, r in zip(x_prior, x_range)]\n",
    "        x0 = x_start\n",
    "        lnprob = get_lnprob(peq, lnprob_prior, 1, 0)\n",
    "        # run MCMC\n",
    "        sampler = mcmc.Sampler(x0, lnprob)\n",
    "        samples, q_sim = sampler.run(sample_nb, burnin)\n",
    "        q_sim = np.array(q_sim)\n",
    "        if n == 1:\n",
    "            # outlet basin: no information passing\n",
    "            q_ensemble[f'b{ws_nb-1}'] = q_sim\n",
    "            plot_series(ensemble=q_sim[:, -days:], true=df[f'q_true_{ws_nb-1}'].values[-days:], title=f'Streamflow at the outlet of $B_{ws_nb-1}$')\n",
    "            q_kde = np.empty((2, n_kde, q_sim.shape[1]))\n",
    "            for i in range(q_kde.shape[2]):\n",
    "                q_kde[:, :, i] = get_kde(q_sim[:, i], nb=n_kde)\n",
    "        else:\n",
    "            # head basin of a dual calibration has prior information\n",
    "            x_head = [get_kde(samples[:, i]) for i in range(4)]\n",
    "\n",
    "    peq = df[['p', 'e']]\n",
    "    area_head = ws_i\n",
    "    area_tail = 1\n",
    "    x0 = [xy[0][np.argmax(xy[1])] for xy in x_head] # most likely value\n",
    "    x0 += [d_start] + x_start\n",
    "    # prior probability distribution is uniform for tail basin\n",
    "    lnprob_prior = [lnprob_from_density(p, *r) for p, r in zip(x_head, x_range)]\n",
    "    lnprob_prior += [lnprob_from_density(d_prior, *d_range)]\n",
    "    x_tail = [uniform_density(*r) for r in x_range]\n",
    "    lnprob_prior += [lnprob_from_density(p, *r) for p, r in zip(x_tail, x_range)]\n",
    "    lnprob = get_lnprob(peq, lnprob_prior, area_head, area_tail, q_kde)\n",
    "    # run MCMC\n",
    "    sampler = mcmc.Sampler(x0, lnprob)\n",
    "    samples, q_sim = sampler.run(sample_nb, burnin)\n",
    "    # get simulated streamflow and uncertainty\n",
    "    q_sim = np.array(q_sim)\n",
    "    # KDE of streamflow time series will be used at next iteration\n",
    "    q_kde = np.empty((2, n_kde, q_sim.shape[1]))\n",
    "    for i in range(q_kde.shape[2]):\n",
    "        q_kde[:, :, i] = get_kde(q_sim[:, i], nb=n_kde)\n",
    "    q_ensemble[f'b{ws_i-1}'] = q_sim\n",
    "    # plot updated streamflow\n",
    "    plot_series(ensemble=q_sim[:, -days:], true=df[f'q_true_{ws_i-1}'].values[-days:], title=f'Streamflow at the outlet of $B_{ws_i-1}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the forward pass accumulates information downstream, the backward pass accumulates information upstream, i.e. *B<sub>0</sub>*'s streamflow is better known than *B<sub>4</sub>*'s streamflow. The information gathered by the two passes has to be combined, which is what the smoothing step does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to merge the forward and the backward passes, since they are complementary in their use of information. This is done by combining their ensemble of simulated streamflows at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ws_i in range(ws_nb):\n",
    "    q_sim = np.vstack((q_ensemble[f'f{ws_i}'], q_ensemble[f'b{ws_i}']))\n",
    "    q_sim[q_sim==np.inf] = np.nan\n",
    "    q_mean = np.nanmean(q_sim, axis=0)\n",
    "    plot_series(q_sim[:, -days:], df[f'q_true_{ws_i}'].values[-days:], mean=q_mean[-days:], title=f'Updated streamflow at the outlet of $B_{ws_i}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showed how the forward-backward algorithm can be applied to hydrology in the context of distributed information, e.g. when sparse water level measurements are spread over the hydrological network, and/or when these measurements are of poor precision. The power of the bayesian framework can be leveraged to take advantage of this situation and pass the information downstream (forward) and upstream (backward), resulting in an efficient use of the overall information. Satellite measurements are well suited to this kind of processing due to the fact that they are spatially interleaved. In particular, satellite-based water level is a good candidate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
